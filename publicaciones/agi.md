---
title: El camino hacia la AGI
description: 
image: https://emirodgar.com/cdn/images/og/estrategia-seo.png
author: Emirodgar
lang: es_ES
sitemap: 1
feed: 1
date: 21-05-2025
folder: ia
permalink: agi
---

De momento lo que tenemos es más incertidumbre que hechos constatados acerca de cuándo llegará la **inteligencia artificial general** (AGI), una forma de IA tan capaz como los humanos en tareas cognitivas.
Uno de los textos más relevantes a día de hoy es el generado por [Google DeepMind](https://archive.ph/AjgJy), donde exploran y comparten sus avances y medidas para acotar potenciales problemas.

# Desarrollo responsable de la inteligencia artificial general (AGI)

El equipo de Google detalla cómo está abordando el desarrollo seguro y responsable de esta tecnología que podría transformar sectores como la salud, la educación, la innovación y la sostenibilidad. Y también de qué manera exploran los potenciales riesgos que podría generar.

## Principales áreas de riesgo

Se identifican cuatro grandes áreas de riesgo de la AGI:

- **Mal uso**: cuando alguien utiliza la IA con fines dañinos, como ciberataques o desinformación. Para evitarlo, se están desarrollando mecanismos de seguridad avanzados que impidan el acceso indebido a las capacidades más peligrosas.
- **Desalineación con los valores humanos**: cuando la IA no entiende correctamente los objetivos humanos o los interpreta mal. Se trabaja en métodos para entrenar a la IA a seguir instrucciones humanas con precisión, detectar desviaciones y mejorar la supervisión mediante sistemas de monitoreo.
- **Accidentes técnicos**
- **Riesgos estructurales**

## Medidas clave

- Desarrollo de sistemas de seguridad avanzados que bloquean capacidades peligrosas.
- Supervisión activa del comportamiento de la IA mediante monitores específicos.
- Investigación en interpretabilidad para que las decisiones de la IA sean más transparentes.
- Uso de técnicas como MONA para asegurar que los planes a largo plazo de la IA sean comprensibles para los humanos.

## Colaboración y gobernanza

- Creación del **AGI Safety Council** para evaluar riesgos y recomendar buenas prácticas.
- Alianzas con entidades externas como **Redwood Research** y **Apollo**.
- Participación en iniciativas como **Frontier Model Forum** para establecer estándares de seguridad.
- Lanzamiento de un curso de formación en seguridad de AGI para investigadores y profesionales.

Los pasos que se están dando son bastante acertados, pero tendremos que ver si llegado el momento se gestionan las decisiones en un comité abierto y consensuado. Eso determinará el futuro y viabilidad del sistema.
